{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Kinetic model of isomerization reaction\n",
    "\n",
    "## Introduction\n",
    "\n",
    "\n",
    "The problem addressed refers to the parameter estimation of the kinetic model of the pyrolysis reaction of bicyclohexane in the vapor phase. This reaction has as product 1,5-hexadien [1] and is exemplified by Figure 1.\n",
    "\n",
    "**Figure 1: Bicyclohexane pyrolysis reaction. Font: [1]**\n",
    "![Tanques](./Imagens/P.jpg)\n",
    "\n",
    "The experimental data for this reaction, in a temperature range of 327 °C to 366 °C, are presented in Table 1.        \n",
    "\n",
    "**Table 1: Experimental data. Font: [1]**   \n",
    "                                               \n",
    "  Temperature / °C | Reagent pressure / mmHg | Time / min | Reagent fraction / % |       $k$ x $10^{5}$\n",
    "  :-------------: |  :----------------------: |:-----------:|:---------------------: |:------------------------:\n",
    "         327.2    |         18.4                        |120              |90.0                  |1.46 \n",
    "         327.2    |         18.3                        |60.0             |94.9                  |1.43\n",
    "         338.9    |         18.3                        |60.0             |88.6                  |3.37\n",
    "             .    |         .                           |.                |.                     |.\n",
    "             .    |         .                           |.                |.                     |.\n",
    "             .    |         .                           |.                |.                     |.\n",
    "         366.3    |         0.45                        |60.0             |46.8                  |21.1  \n",
    "         366.3    |         0.30                        |30.0             |47.6                  |21.8\n",
    "         366.3    |         0.25                        |60.0             |49.7                  |19.4\n",
    "           \n",
    "           \n",
    "The reaction kinetic model is given by [1]: \n",
    "\n",
    "$y = \\exp\\left[-K_0\\cdot t \\cdot \\exp\\left(-E(\\frac{1}{T}\\right))\\right]$,                  (1)\n",
    "\n",
    "on what $y$ is the reagent fraction, $t$ is the time, $T$ is the temperature (K) and $k_o$ and $E$ are the parameters that will be estimated.\n",
    "\n",
    "The optimization problem to be solved uses the objective function of least squares weighted by the inverse of the variance, according to [2]:\n",
    "\n",
    "$\\min_{ko,E} \\sum_{i=1}^{NE} \\left(\\frac{y^{exp}_i-y_i(k_o,E)}{u^2_{y_i}}\\right)$ (2)\n",
    "\n",
    "subject to (1).\n",
    "\n",
    "The following symbols will be used to solve this problem in the MT_PEU:\n",
    "\n",
    "* Symbols of the independent quantities (time and temperature): t, T\n",
    "* Symbols of the dependent quantities (reagent fraction): y\n",
    "* Symbols of the parameters: ko, E\n",
    "\n",
    "## Packages importing\n",
    "\n",
    "Importing libraries (packages) needed to run the code.\n",
    "\n",
    "* **MT_PEU**: library that contains the main functionalities of the tool\n",
    "\n",
    "    * Import the class **EstimacaoNaoLinear**, that will be used in this non-linear estimation example.\n",
    "\n",
    "* **casadi**: library for symbolic computation\n",
    "\n",
    "    * only the function **exp** (exponential) will be required to build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MT_PEU import EstimacaoNaoLinear\n",
    "from casadi import exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation\n",
    "\n",
    "The model (1) represents the behavior of the dependent quantity in which the parameters $k_o$ and $E$ will be estimated.\n",
    "\n",
    "This model is then defined in the form of a python subroutine (**def**) and represented by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model (param, x, args):\n",
    "\n",
    "    ko, E = param[0], param[1]\n",
    "    time, T = x[:,0], x[:,1] \n",
    "    \n",
    "    return exp(-ko*time*exp(-E*(1/T-1./630.)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class initialization\n",
    "\n",
    "The first step to perform the estimation is to configure the class **EstimacaoNaoLinear** through the inclusion of basic information.:\n",
    "\n",
    "* The model,\n",
    "* List of symbols of the independent quantities *(x)*; \n",
    "* List of symbols of the dependent quantities *(y)*; \n",
    "* List of symbols of the parameters *(param)*;\n",
    "* List of symbols for parameters written in LaTex *(label_latex_param)*;\n",
    "* List of symbols for quantities x written in LaTex *(label_latex_x)*;\n",
    "* List of units of measurement for independent quantities *(units_y)*;\n",
    "* List of units of measurement of dependent quantities *(units_x)*;\n",
    "* List of units of measurement of the parametersb*(units_param)*;\n",
    "* The project name, the folder's name where the results will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Estime = EstimacaoNaoLinear(Model, symbols_x=[r't','Tao'], units_x=['s','K'], label_latex_x=[r'$t$','$T$'],\n",
    "                            symbols_y=[r'y'], units_y=['adm'],\n",
    "                            symbols_param=['ko','E'], units_param=['adm','K'],label_latex_param=[r'$k_o$',r'$E$'],\n",
    "                            Folder='Exemple5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data inclusion\n",
    "\n",
    "The experimental data provided in Table 1 of the dependent quantity (y) and the independent quantities (t and T), are presented below in the form of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time\n",
    "time = [120.0,60.0,120.0,60.0,30.0,15.0,45.1,90.0,150.0,60.0,60.0,30.0,150.0,90.4,120.0,60.0,60.0,60.0,30.0,\n",
    "         45.1,30.0,45.0,15.0,90.0,25.0,60.1,60.0,30.0,60.0]\n",
    "\n",
    "#Temperature\n",
    "temperature = [600.0,612.0,612.0,620.0,620.0,620.0,620.0,620.0,620.0,620.0,620.0,620.0,620.0,620.0,620.0,620.0,620.0,\n",
    "               620.0,631.0,631.0,631.0,631.0,639.0,639.0,639.0,639.0,639.0,639.0,639.0]\n",
    "\n",
    "#Reagent fraction\n",
    "y1 = [0.9,0.886,0.791,0.787,0.877,0.938,0.827,0.696,0.582,0.795,0.790,0.883,0.576,0.715,0.673,0.802,0.804,0.804,0.764,\n",
    "     0.688,0.802,0.695,0.808,0.309,0.689,0.437,0.425,0.659,0.449]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MT_PEU **needs** the **uncertainties of the experimental data** (ux1, ux2, uy1) to be informed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "uxtime = [1]*29\n",
    "uxtemperature = [5]*29\n",
    "uy1 = [1]*29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entering the experimental data in MT_PEU:**\n",
    "\n",
    "The *setDados* method is used to include the data for dependent and independent quantities. Syntax:\n",
    "\n",
    "* Quantity identification, whether it is independent or dependent: 0 or 1 (respectively)\n",
    "* The experimental data and their uncertainties must be entered in sequence in the form of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Estime.setDados(data={0:[(time,uxtime),(temperature,uxtemperature)],1:[(y1,uy1)]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The setConjunto method defines that the experimental data previously entered will be used as a data set for which parameters will be estimated. The degrees of freedom for the quantity $ x $ and $ y $ are defined in *glx* and *gly*, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "In this example, the user can choose the algorithm to be used in the optimization. \n",
    "Available: 'ipopt', 'bonmin' and 'sqpmethod'.\n",
    "\n",
    "If the user does not choose any optimization method, the default algorithm will be used: ipopt, with initial estimative equal to [0.005, 20000.000].\n",
    "\n",
    "**Lower_bound** and **upper_bound:** They refer to the upper and lower limits of the parameters related to their physical characteristics;\n",
    "\n",
    "**algorithm:** Informs the optimization algorithm that will be used. Each algorithm has its own keywords;\n",
    "\n",
    "**optimizationReport:** Informs whether the optimization report should be created (True or False);\n",
    "\n",
    "**parametersReport:** Informs whether the parameters report should be created (True or False)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit http://projects.coin-or.org/Ipopt\n",
      "******************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Estime.optimize(initial_estimative= [0.005, 20000.000],algorithm='ipopt', lower_bound=[0.006,15000], upper_bound=[100,20000],\n",
    "                optimizationReport = True, parametersReport = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters uncertainty\n",
    "\n",
    "\n",
    "In this example, it is possible to choose the method used to evaluate uncertainty. \n",
    "Available: 2InvHessiana, Geral, SensibilidadeModelo. \n",
    "By definition the likelihood region filling is 'True', if necessary this option can be changed.\n",
    "\n",
    "If the user **does not** have an interest in **evaluating the uncertainty of the parameters**, just **do not** perform **Estime.parametersUncertainty**.\n",
    "\n",
    "**uncertaintyMethod:** method for calculating the covariance matrix of the parameters.\n",
    "\n",
    "**parametersReport:** Informs whether the parameters report should be created (True or False).\n",
    "\n",
    "**objectiveFunctionMapping:** Deals with mapping the objective function (True or False).\n",
    "\n",
    "**limite_inferior:** Lower limit of parameters for mapping the coverage region.\n",
    "\n",
    "**limite_superior:** Upper limit of parameters for mapping the coverage region.\n",
    "\n",
    "**iterations:** Number of iterations to perform the mapping of the objective function. The higher the better mapping, but it increases the execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Estime.parametersUncertainty(uncertaintyMethod='Geral',objectiveFunctionMapping=False, limite_inferior=[0.2,15000], limite_superior=[3.6,19000],\n",
    "                             parametersReport = True,  iterations=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and residual analysis\n",
    "\n",
    "The prediction method evaluates the dependent quantity based on the estimated parameters. To give more credibility to the results, the covariance matrix of the estimates obtained through the model is also evaluated. \n",
    " \n",
    "The residue analysis provides information concerning the quality of the model, for example: (i) trend relationship not included in the model, (ii) undue correlations, etc. Such assessments are based on statistical tests such as homoscedasticity and $ðchi^2$.\n",
    "\n",
    "The prediction and the residual analysis are preferably performed with validation data when available.\n",
    "\n",
    "**export_y:** Exports the calculated data of y, its uncertainty, and degrees of freedom in a txt with comma separation (True or False);\n",
    "\n",
    "**export_y_xls:** Exports the calculated data of y, its uncertainty, and degrees of freedom in a xls (True or False);\n",
    "\n",
    "**export_cov_y:** Exports the covariance matrix of y (True or False);\n",
    "\n",
    "**export_x:** Exports the calculated data of x, its uncertainty, and degrees of freedom in a txt with comma separation(True or False);\n",
    "\n",
    "**export_cov_x:** Exports the covariance matrix of x (True or False)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artur\\anaconda3\\lib\\site-packages\\statsmodels\\stats\\diagnostic.py:559: FutureWarning: The value returned will change to a single DataFrame after 0.12 is released.  Set return_df to True to use to return a DataFrame now.  Set return_df to False to silence this warning.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "Estime.prediction(export_y=True,export_y_xls=True, export_cov_y=True, export_x=True, export_cov_x=True)\n",
    "Estime.residualAnalysis(report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots and reports\n",
    "\n",
    "At this stage, the results obtained by the program are exported: reports and graphs. \n",
    "The graphs are generated according to the steps that have been performed. In the reports, information about the statistical tests, objective function value, covariance matrix of the parameters, optimization status, among others, are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x240 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Estime.plots()\n",
    "Estime.reports()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: Validation\n",
    "\n",
    "If the user wishes, it is possible to do the same analysis as before with the prediction data. \n",
    "The procedure to be followed is similar to the one previously carried out. The only difference is in the argument inserted in the setConjunto method.\n",
    "Instead of \"dataType = estimacao\" it becomes \"dataType = predicao\". It is necessary to enter at least 4 data for each prediction variable.\n",
    "\n",
    "## Data inclusion\n",
    "\n",
    "**Setting the validation data set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input 1\n",
    "time = [60.0,120.0,60.0,60.0,60.0,60.0,60.0,30.0,30.0,90.0,60.0,30.0]\n",
    "# input 2\n",
    "temperature = [600.0,612.0,612.0,620.0,620.0,620.0,620.0,639.0,639.0,620.0,620.0,631.0]\n",
    "# output\n",
    "y = [0.949,0.785,0.890,0.782,0.800,0.802,0.799,0.655,0.638,0.712,0.794,0.717]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncertainty measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "uxtime = [0.2]*12\n",
    "uxtemperature = [0.2]*12\n",
    "uy1 = [0.2]*12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the observed data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data vectors and their uncertainties must have the same number of points.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-7b30c8bd7fc6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mEstime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetDados\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muxtime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muxtemperature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muy1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\PycharmProjects\\MT_PEU\\MT_PEU.py\u001b[0m in \u001b[0;36msetDados\u001b[1;34m(self, data, worksheet)\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The data input can be either in dictionary format or string \"\u001b[0m\u001b[1;34m\"excel file name\"\u001b[0m\u001b[1;34m\", check if the input follows any of these formats\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__validacaoDadosEntrada\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__validacaoDadosEntrada\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\MT_PEU\\MT_PEU.py\u001b[0m in \u001b[0;36m__validacaoDadosEntrada\u001b[1;34m(self, dados, udados, NV)\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdados\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mudados\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 660\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data vectors and their uncertainties must have the same number of points.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mudados\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNV\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparametros\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNV\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# Verificar se há graus de liberdade suficiente\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data vectors and their uncertainties must have the same number of points."
     ]
    }
   ],
   "source": [
    "Estime.setDados(data={0:[(time,uxtime),(temperature,uxtemperature)],1:[(y,uy1)]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the previous data set to be used to validation. The degrees of freedom for the quantity $ x $ and $ y $ are defined in *glx* and *gly*, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-b5fec669aca1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating model predictions for the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Estime.prediction(export_y=True,export_y_xls=True, export_cov_y=True, export_x=True, export_cov_x=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating residuals and quality index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Estime.residualAnalysis(report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the main results\n",
    "\n",
    "In this step, the results obtained by the program are the graphics generated according to the steps that were performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x240 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Estime.plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References: \n",
    "\n",
    "[1] SRINIVASAN, R.; LEVI, A. A.. Kinetics of the Thermal Isomerization of Bicyclo [2.1.1 ]hexane. Journal Of The American Chemical Society, [s.l.], v. 85, n. 21, p.3363-3365, 5 nov. 1963. American Chemical Society (ACS)\n",
    "\n",
    "[2] SCHWAAB, M.M.;PINTO, J.C. Análise de Dados Experimentais I: Fundamentos da Estátistica e Estimação de Parâmetros. \n",
    "Rio de Janeiro: e-papers, 2007.\n",
    "\n",
    "INMETRO.: Avaliação de dados de medição — Guia para a expressão de incerteza de medição. Rio de Janeiro: Jcgm, 2008."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
